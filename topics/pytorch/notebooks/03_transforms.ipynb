{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 使用transforms对数据进行处理使其适合训练。",
   "id": "c149b4a7eb218ee4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "所有 TorchVision 数据集都有两个参数\n",
    "\n",
    "`-transform` 用于修改特征，`-target_transform` 用于修改标签"
   ],
   "id": "41f3ba29404477e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "FashionMNIST 特征采用 PIL 图像格式，标签是整数。对于训练，我们需要将特征作为归一化张量，标签作为 one-hot 编码张量。为了进行这些转换，我们使用 `ToTensor` 和 `Lambda`。",
   "id": "5255fd0a0c30569b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T09:53:25.530609Z",
     "start_time": "2025-02-19T09:53:25.456819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=r\"D:\\Github\\learning-repository\\assets\\data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ],
   "id": "33f3bb41b28fd389",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 以下是对于scatter操作的讲解\n",
    "```\n",
    "self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\n",
    "self[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\n",
    "self[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
    "```"
   ],
   "id": "6b41cfa779da186c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T09:53:25.577195Z",
     "start_time": "2025-02-19T09:53:25.537128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "src = torch.arange(1, 11).reshape((2, 5))\n",
    "src"
   ],
   "id": "dd37b35219c84987",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T09:53:25.624294Z",
     "start_time": "2025-02-19T09:53:25.601740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "index = torch.tensor([[0, 1, 2, 0]])\n",
    "torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)"
   ],
   "id": "15567085b38154ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 4, 0],\n",
       "        [0, 2, 0, 0, 0],\n",
       "        [0, 0, 3, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T09:53:26.834182Z",
     "start_time": "2025-02-19T09:53:26.821661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n",
    "torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)"
   ],
   "id": "b6051c6a20ae50",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 0, 0],\n",
       "        [6, 7, 0, 0, 8],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T09:53:27.165138Z",
     "start_time": "2025-02-19T09:53:27.124151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
    "           1.23, reduce='multiply')\n",
    "torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n",
    "           1.23, reduce='add')"
   ],
   "id": "81174354a72dbf1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 2.0000, 3.2300, 2.0000],\n",
       "        [2.0000, 2.0000, 2.0000, 3.2300]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch--myenv",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
