{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 先决条件代码",
   "id": "d28a050b15ae59df"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-24T03:29:49.287819Z",
     "start_time": "2025-02-24T03:29:42.472283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=r\"D:\\Github\\learning-repository\\assets\\data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=r\"D:\\Github\\learning-repository\\assets\\data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 超参数\n",
    "-`Epochs`数 遍历数据集的次数\n",
    "-批次大小 在更新参数之前通过网络传播的数据样本数\n",
    "-学习率 在每个批次/epoch 更新模型参数的程度。较小的值产生较慢的学习速度，而较大的值可能导致训练期间出现不可预测的行为。\n"
   ],
   "id": "be20ac6d109c917c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:34:42.177763Z",
     "start_time": "2025-02-24T03:34:42.159463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ],
   "id": "39af3db75621e7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 优化循环\n",
    "优化循环的每次迭代称为一个epoch，每个epoch由两个主要部分组成\n",
    "训练循环：迭代训练数据集并尝试收敛到最佳参数。\n",
    "验证/测试循环：迭代测试数据集以检查模型性能是否正在提高。"
   ],
   "id": "9832498136d6ebd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 损失函数\n",
    "常见的损失函数包括用于回归任务的 `nn.MSELoss`（均方误差）和用于分类的 `nn.NLLLoss`（负对数似然）。`nn.CrossEntropyLoss` 结合了 `nn.LogSoftmax` 和 `nn.NLLLoss`。\n",
    "\n",
    "我们将模型的输出 `logits` 传递给 `nn.CrossEntropyLoss`，它将标准化 `logits` 并计算预测误差。\n"
   ],
   "id": "23666e0967e69ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:34:44.547475Z",
     "start_time": "2025-02-24T03:34:44.530900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "id": "c7d0b35f0ca28bc5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 优化器\n",
    "所有优化逻辑都封装在 `optimizer` 对象中。在这里，我们使用 SGD 优化器\n",
    "我们通过注册需要训练的模型参数并传入学习率超参数来初始化优化器。"
   ],
   "id": "3297dc4568494f1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:35:49.978839Z",
     "start_time": "2025-02-24T03:35:49.962320Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)",
   "id": "9b2542bb2c1bad08",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 完整实现\n",
   "id": "6a05dea861316028"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:38:08.785850Z",
     "start_time": "2025-02-24T03:38:08.757087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)#计算损失\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()# 反向传播\n",
    "        optimizer.step()#调整模型参数\n",
    "        optimizer.zero_grad()#梯度清零\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "id": "4fb64ee480e3795a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:41:36.218988Z",
     "start_time": "2025-02-24T03:38:53.625209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "id": "162624991833c4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.301309  [   64/60000]\n",
      "loss: 2.301266  [ 6464/60000]\n",
      "loss: 2.280473  [12864/60000]\n",
      "loss: 2.280265  [19264/60000]\n",
      "loss: 2.278792  [25664/60000]\n",
      "loss: 2.232024  [32064/60000]\n",
      "loss: 2.247642  [38464/60000]\n",
      "loss: 2.210382  [44864/60000]\n",
      "loss: 2.202325  [51264/60000]\n",
      "loss: 2.184188  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 41.2%, Avg loss: 2.182625 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.184051  [   64/60000]\n",
      "loss: 2.185746  [ 6464/60000]\n",
      "loss: 2.131168  [12864/60000]\n",
      "loss: 2.143637  [19264/60000]\n",
      "loss: 2.117091  [25664/60000]\n",
      "loss: 2.045929  [32064/60000]\n",
      "loss: 2.070114  [38464/60000]\n",
      "loss: 1.998127  [44864/60000]\n",
      "loss: 1.996141  [51264/60000]\n",
      "loss: 1.928586  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.9%, Avg loss: 1.938557 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.965810  [   64/60000]\n",
      "loss: 1.946470  [ 6464/60000]\n",
      "loss: 1.833437  [12864/60000]\n",
      "loss: 1.858107  [19264/60000]\n",
      "loss: 1.780607  [25664/60000]\n",
      "loss: 1.708422  [32064/60000]\n",
      "loss: 1.723197  [38464/60000]\n",
      "loss: 1.626254  [44864/60000]\n",
      "loss: 1.648863  [51264/60000]\n",
      "loss: 1.533288  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.566487 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.629876  [   64/60000]\n",
      "loss: 1.596763  [ 6464/60000]\n",
      "loss: 1.446755  [12864/60000]\n",
      "loss: 1.506724  [19264/60000]\n",
      "loss: 1.412963  [25664/60000]\n",
      "loss: 1.379715  [32064/60000]\n",
      "loss: 1.392624  [38464/60000]\n",
      "loss: 1.313150  [44864/60000]\n",
      "loss: 1.352691  [51264/60000]\n",
      "loss: 1.245863  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.283196 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.356304  [   64/60000]\n",
      "loss: 1.336696  [ 6464/60000]\n",
      "loss: 1.172857  [12864/60000]\n",
      "loss: 1.272825  [19264/60000]\n",
      "loss: 1.166483  [25664/60000]\n",
      "loss: 1.168483  [32064/60000]\n",
      "loss: 1.187123  [38464/60000]\n",
      "loss: 1.121869  [44864/60000]\n",
      "loss: 1.165962  [51264/60000]\n",
      "loss: 1.077663  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.2%, Avg loss: 1.107290 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.174764  [   64/60000]\n",
      "loss: 1.174081  [ 6464/60000]\n",
      "loss: 0.995916  [12864/60000]\n",
      "loss: 1.126363  [19264/60000]\n",
      "loss: 1.013808  [25664/60000]\n",
      "loss: 1.027972  [32064/60000]\n",
      "loss: 1.059648  [38464/60000]\n",
      "loss: 1.000933  [44864/60000]\n",
      "loss: 1.044065  [51264/60000]\n",
      "loss: 0.972512  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.993938 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.049281  [   64/60000]\n",
      "loss: 1.069470  [ 6464/60000]\n",
      "loss: 0.875877  [12864/60000]\n",
      "loss: 1.029910  [19264/60000]\n",
      "loss: 0.917458  [25664/60000]\n",
      "loss: 0.929829  [32064/60000]\n",
      "loss: 0.976209  [38464/60000]\n",
      "loss: 0.922500  [44864/60000]\n",
      "loss: 0.958898  [51264/60000]\n",
      "loss: 0.903320  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.9%, Avg loss: 0.917346 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.957732  [   64/60000]\n",
      "loss: 0.998060  [ 6464/60000]\n",
      "loss: 0.791161  [12864/60000]\n",
      "loss: 0.962604  [19264/60000]\n",
      "loss: 0.853259  [25664/60000]\n",
      "loss: 0.859076  [32064/60000]\n",
      "loss: 0.918072  [38464/60000]\n",
      "loss: 0.870820  [44864/60000]\n",
      "loss: 0.897291  [51264/60000]\n",
      "loss: 0.854588  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.1%, Avg loss: 0.862963 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.888470  [   64/60000]\n",
      "loss: 0.945823  [ 6464/60000]\n",
      "loss: 0.728758  [12864/60000]\n",
      "loss: 0.913515  [19264/60000]\n",
      "loss: 0.807683  [25664/60000]\n",
      "loss: 0.806746  [32064/60000]\n",
      "loss: 0.874892  [38464/60000]\n",
      "loss: 0.835391  [44864/60000]\n",
      "loss: 0.851628  [51264/60000]\n",
      "loss: 0.817732  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.822388 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.834256  [   64/60000]\n",
      "loss: 0.904957  [ 6464/60000]\n",
      "loss: 0.680784  [12864/60000]\n",
      "loss: 0.876238  [19264/60000]\n",
      "loss: 0.773207  [25664/60000]\n",
      "loss: 0.766693  [32064/60000]\n",
      "loss: 0.840755  [38464/60000]\n",
      "loss: 0.809802  [44864/60000]\n",
      "loss: 0.816345  [51264/60000]\n",
      "loss: 0.788421  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.7%, Avg loss: 0.790397 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 保存和加载模型\n",
   "id": "85fe4010e86d7750"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:49:10.514796Z",
     "start_time": "2025-02-24T03:49:10.493697Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 9,
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "torch.save(model.state_dict(), 'model_weights.pth')# 保存模型权重参数"
   ],
   "id": "e9912a9c6f511021"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:51:05.175493Z",
     "start_time": "2025-02-24T03:51:05.156298Z"
    }
   },
   "cell_type": "code",
   "source": "model1 = NeuralNetwork()  #实例化新模型",
   "id": "519a0987d61fe778",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:52:10.362727Z",
     "start_time": "2025-02-24T03:52:10.322797Z"
    }
   },
   "cell_type": "code",
   "source": "model1.load_state_dict(torch.load('model_weights.pth',weights_only=True))# 将模型权重参数加载到新模型",
   "id": "9493499178be5e5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T03:52:18.483018Z",
     "start_time": "2025-02-24T03:52:18.466534Z"
    }
   },
   "cell_type": "code",
   "source": "model1.eval() #请务必在推理前调用 model.eval() 方法，将 dropout 和批归一化层设置为评估模式。未能这样做将导致不一致的推理结果。",
   "id": "390136805537f437",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b8cf6b6c7c1dc896"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch--myenv",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
